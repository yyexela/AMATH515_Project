{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Project Description\n",
    "\n",
    "Modern deep learning hinges on variants of stochastic gradient descent. Give an overview of some of the algorithms (ADAM,\n",
    "RMSProp, Adagrad,momentum, etc.) and stepsizing schemes (learning rate decay, cosine annealing, superconvergence, hyper-\n",
    "gradient learning rate adaptation, etc.) and perform an empirical comparison of their performance on some test problems of\n",
    "your choice. Obviously, no comparison here can be anywhere close to exhaustive due to the overabundance of deep learning op-\n",
    "timization papers, so just go through a handful of ideas that you find interesting. If you want to do this with realistic (somewhat\n",
    "large) networks, you’ll probably need access to some GPUs. This will take a bit more work (but should still be doable!) to do\n",
    "as a project if you don’t have any previous experience in deep learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Notes:\n",
    "- Test problems:\n",
    "  - [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "    - image classification\n",
    "  - [minGPT](https://github.com/karpathy/minGPT?tab=readme-ov-file)\n",
    "    - Text Generation (but trained by filling in missing words)\n",
    "  - [California Housing](https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html)\n",
    "    - Regression (predict housing cost)\n",
    "  - Simple 1D optimization to visualize things\n",
    "    - Rosenbrock function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Text Generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alexey/Git/AMATH515/submodules\n",
      "GPU Available? False\n"
     ]
    }
   ],
   "source": [
    "# Reload external files when running cells\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add custom package to import path and import it\n",
    "file_dir = pathlib.Path().resolve()\n",
    "pkg_dir = os.path.join(file_dir, \"submodules\")\n",
    "print(pkg_dir)\n",
    "sys.path.insert(0, pkg_dir)\n",
    "sys.path.insert(0, os.path.join(pkg_dir, \"minGPT\"))\n",
    "sys.path.insert(0, os.path.join(pkg_dir, \"amath515_pkg\"))\n",
    "from amath515_pkg.src import *\n",
    "\n",
    "# Load minGTP\n",
    "from mingpt.model import GPT\n",
    "from mingpt.trainer import Trainer\n",
    "from mingpt.utils import CharDataset, CfgNode as CN\n",
    "\n",
    "# Load config file\n",
    "pkg_config = helpers.get_config()\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(pkg_config['mingpt_np_seed'])\n",
    "torch.manual_seed(pkg_config['mingpt_torch_seed'])\n",
    "\n",
    "# Print matplotlibe plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Make sure Torch is installed and see if a GPU is available\n",
    "print(\"GPU Available?\",torch.cuda.is_available())\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tiny Shakespeare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 1115394 characters, 65 unique.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# To download tiny-shakespeare, go to https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt and put it in the \"Datasets\" folder\n",
    "mingpt_config = helpers.get_minGPT_config()\n",
    "with open(os.path.join(file_dir, 'Datasets', 'tiny-shakespeare.txt'), 'r') as file:\n",
    "    tiny_shakespeare = file.read()\n",
    "train_dataset = CharDataset(mingpt_config.data, tiny_shakespeare)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure model and trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 2.71M\n",
      "running on device cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# construct the model\n",
    "mingpt_config.model.vocab_size = train_dataset.get_vocab_size()\n",
    "mingpt_config.model.block_size = train_dataset.get_block_size()\n",
    "model = GPT(mingpt_config.model)\n",
    "\n",
    "# prepare for training otherwise\n",
    "# construct the trainer object\n",
    "mingpt_config.trainer.max_iters = pkg_config['mingpt_iters']\n",
    "mingpt_config.trainer.optimizer_str = pkg_config['mingpt_SGD_method']\n",
    "mingpt_config.trainer.scheduler_str = pkg_config['mingpt_Scheduler']\n",
    "trainer = Trainer(mingpt_config.trainer, model, train_dataset)\n",
    "\n",
    "# construct callback function\n",
    "callback = lambda x: training.min_gpt_batch_end_callback(model, mingpt_config, train_dataset, x)\n",
    "trainer.set_callback('on_batch_end', callback)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### GPT Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, lr 0.000500\n",
      "---------------------------------\n",
      "Saving model to \"/home/alexey/Git/AMATH515/Saved_Models/mingpt.ckpt\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# run the optimization\n",
    "trainer.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.224494457244873]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(trainer.losses)\n",
    "print(trainer.iter_num)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
